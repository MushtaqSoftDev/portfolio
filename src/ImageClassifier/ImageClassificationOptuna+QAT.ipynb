{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c8b257c0-b71b-47b1-bbbc-af707d1955aa",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 1 - Import\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "# Step 1 - Import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import optuna\n",
        "from torch.ao.quantization import (\n",
        "    prepare_qat, convert, get_default_qat_qconfig\n",
        ")\n",
        "\n",
        "import torch.onnx\n",
        "print(\"Torch version\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3f4661-123e-41b0-b9d8-abca4717025d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['cats', 'dogs']\n"
          ]
        }
      ],
      "source": [
        "# Step 2 - Dataset & Transform\n",
        "# IMPORTANT: For 3-class training, your folders should be:\n",
        "#   myImages/train/cats\n",
        "#   myImages/train/dogs\n",
        "#   myImages/train/others\n",
        "#   myImages/test/cats\n",
        "#   myImages/test/dogs\n",
        "#   myImages/test/others\n",
        "# ImageFolder will discover classes in alphabetical order, so with\n",
        "# ['cats', 'dogs', 'others'] we get:\n",
        "#   index 0 -> cats, index 1 -> dogs, index 2 -> others\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"myImages/train\", transform=transform)\n",
        "test_dataset = datasets.ImageFolder(\"myImages/test\", transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e75dbded-596d-457b-973b-79d881537acd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3 - Model Definition\n",
        "# NOTE:\n",
        "# - We want 3 explicit classes: ['cats', 'dogs', 'others'].\n",
        "# - So the final layer should output 3 logits (for each class).\n",
        "# - ImageFolder will map folders in alphabetical order, so make sure your\n",
        "#   train/test folders look like:\n",
        "#     myImages/train/cats\n",
        "#     myImages/train/dogs\n",
        "#     myImages/train/others\n",
        "#     myImages/test/cats\n",
        "#     myImages/test/dogs\n",
        "#     myImages/test/others\n",
        "#   and we will interpret index 0 -> cats, 1 -> dogs, 2 -> others.\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        # 3 outputs: 0=cat, 1=dog, 2=other\n",
        "        self.fc2 = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ec7603-6d7d-41cf-b11d-3d5feacd733b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4 - OPTUNA(Hyperparameter Tuning)\n",
        "# Its good to choose best lr (learning rate) not like a fixed always, Optuna tries multiple learning rates automatically and picks best.\n",
        "# Define Objective Function\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = SimpleClassifier()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(3):\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = loss_fn(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            preds = model(x).argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee91ab40-4ab5-41fd-9373-7e7b12e7050f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2026-01-01 19:20:54,714] A new study created in memory with name: no-name-52b93d62-17d7-4e3b-b9e7-0b9211d63af3\n",
            "/home/ahmad/pytorch/lib/python3.13/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "[I 2026-01-01 19:20:54,912] Trial 0 finished with value: 1.0 and parameters: {'lr': 0.00020893793011634825}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:55,099] Trial 1 finished with value: 0.5 and parameters: {'lr': 0.00012275960600518357}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:55,285] Trial 2 finished with value: 0.5 and parameters: {'lr': 0.00025534445320197726}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:55,469] Trial 3 finished with value: 0.5 and parameters: {'lr': 0.008656909350357936}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:55,663] Trial 4 finished with value: 0.5 and parameters: {'lr': 0.00020078310444734574}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:55,880] Trial 5 finished with value: 1.0 and parameters: {'lr': 0.00048144570991253213}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:56,067] Trial 6 finished with value: 0.5 and parameters: {'lr': 0.00248856050349762}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:56,264] Trial 7 finished with value: 0.5 and parameters: {'lr': 0.0002505715134136933}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:56,478] Trial 8 finished with value: 0.5 and parameters: {'lr': 0.005494280016606192}. Best is trial 0 with value: 1.0.\n",
            "[I 2026-01-01 19:20:56,672] Trial 9 finished with value: 0.5 and parameters: {'lr': 0.009786956626298617}. Best is trial 0 with value: 1.0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LR: {'lr': 0.00020893793011634825}\n"
          ]
        }
      ],
      "source": [
        "# Run Optuna\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best LR:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a45685-4308-4b55-a522-f50161c93294",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss: 2.3864\n",
            "Epoch 2 Loss: 2.1350\n",
            "Epoch 3 Loss: 1.9161\n",
            "Epoch 4 Loss: 1.7318\n",
            "Epoch 5 Loss: 1.5756\n"
          ]
        }
      ],
      "source": [
        "# STEP 5 - Train Final Model using best LR\n",
        "best_lr = study.best_params[\"lr\"]\n",
        "\n",
        "model = SimpleClassifier()\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(model(images), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f030b9-7c6a-4a9a-a2ec-a1aee8794447",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save float32 before QAT \n",
        "torch.save(model.state_dict(), \"fp32_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af9511da-da51-4fe5-b51c-184296c2aa91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4551/2495038666.py:6: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  prepare_qat(model, inplace=True)\n",
            "/home/ahmad/pytorch/lib/python3.13/site-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# STEP 6 - Quantization Aware Training (QAT)\n",
        "# PREPARE Model for QAT\n",
        "model.train()\n",
        "model.qconfig = get_default_qat_qconfig(\"fbgemm\")\n",
        "\n",
        "prepare_qat(model, inplace=True)\n",
        "\n",
        "# Fine-tune with QAT\n",
        "for epoch in range(3):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(model(images), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d34437-48e8-413b-90da-846f3bff951d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# after QAT training reload float32 Model\n",
        "fp32_model = SimpleClassifier()\n",
        "fp32_model.load_state_dict(torch.load(\"fp32_model.pth\"))\n",
        "fp32_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f93240-5bc8-4d09-86bc-ff4d0d15ec79",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QAT Model Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "# Step 7 - Evaluate after QAT\n",
        "# STEP 7 - Evaluate QAT model\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(\"QAT Model Accuracy:\", correct / total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7e85a29-5ae0-4514-92ac-c540fc14bbfd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Label: 1\n",
            "Predicted: 1\n"
          ]
        }
      ],
      "source": [
        "# STEP 8 - Test single image\n",
        "# Single image prediction\n",
        "example_img, example_label = test_dataset[1]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(example_img.unsqueeze(0))\n",
        "    pred = torch.argmax(output)\n",
        "\n",
        "print(\"True Label:\", example_label)\n",
        "print(\"Predicted:\", pred.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de6106c-a105-4e8d-be46-e9e2b8ecf613",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4551/599651488.py:2: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized_model = torch.ao.quantization.convert(model.eval(), inplace=False)\n"
          ]
        }
      ],
      "source": [
        "# Step 9 - Convert to Quantized Model\n",
        "#quantized_model = torch.ao.quantization.convert(model.eval(), inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c20a3c9-a489-4d50-9d09-6b6013f02098",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `SimpleClassifier([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `SimpleClassifier([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "ONNX model exported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Finally export model (ONNX for deployment)\n",
        "# Export as a single, self-contained ONNX file (no external .data file),\n",
        "# so it can be loaded directly in the browser with onnxruntime-web.\n",
        "\n",
        "dummy_input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "torch.onnx.export(\n",
        "    fp32_model,\n",
        "    dummy_input,\n",
        "    \"cat-dog_classification.onnx\",\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    opset_version=18,\n",
        "    use_external_data_format=False,\n",
        ")\n",
        "\n",
        "print(\"ONNX model exported successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
